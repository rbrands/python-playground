{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Machine Learning Basics: Iris Classification\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a simple machine learning workflow using the famous Iris dataset. We'll build a model that can automatically identify iris flower species based on physical measurements.\n",
    "\n",
    "## The Problem\n",
    "Imagine you're a botanist who finds an iris flower and measures:\n",
    "- Sepal length (cm)\n",
    "- Sepal width (cm)\n",
    "- Petal length (cm)\n",
    "- Petal width (cm)\n",
    "\n",
    "**Goal:** Predict which of the 3 iris species it belongs to:\n",
    "- Iris Setosa\n",
    "- Iris Versicolor\n",
    "- Iris Virginica\n",
    "\n",
    "## Why Machine Learning?\n",
    "Instead of manually creating rules, we'll let the model **learn patterns** from 150 known examples, then use those patterns to classify new flowers automatically.\n",
    "\n",
    "## Dataset\n",
    "- **Size:** 150 flowers (50 of each species)\n",
    "- **Features:** 4 measurements per flower\n",
    "- **Target:** Species classification (3 classes)\n",
    "- **Source:** Built into scikit-learn (no external files needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### Descriptive statistics on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data      # Features: the 4 measurements\n",
    "y = iris.target    # Labels: species (0, 1, or 2)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = iris.target_names[y]\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Species: {iris.target_names}\")\n",
    "print(df.describe())\n",
    "print(df.groupby('species').size())\n",
    "print(\"\\nDistribution of length values\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "df.hist()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### The first rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Split Data into Training and Test Sets\n",
    "\n",
    "We split the data into two parts:\n",
    "- **70% Training data:** The model learns patterns from this\n",
    "- **30% Test data:** We use this to evaluate how well the model works on unseen data\n",
    "\n",
    "This prevents \"cheating\" - the model can't just memorize answers.\n",
    "The Iris dataset is already prepared:\n",
    "- x holds the features, 4 values\n",
    "- y holds the target, the iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data: 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,      # 30% for testing\n",
    "    random_state=7     # Fixed seed for reproducibility\n",
    ")\n",
    "\n",
    "# Show the split\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Train the Model\n",
    "\n",
    "We'll use a **Decision Tree Classifier** - a model that learns a series of yes/no questions to classify flowers.\n",
    "\n",
    "The model will analyze the training data and automatically discover patterns like:\n",
    "- \"If petal length < 2.5cm, then it's Setosa\"\n",
    "- \"If petal width > 1.8cm, then it's Virginica\"\n",
    "\n",
    "We use a max depth of 3 that provides a good balance as starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model on our training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✓ Model training complete!\")\n",
    "print(f\"\\nModel type: {type(model).__name__}\")\n",
    "print(f\"Max depth: {model.max_depth}\")\n",
    "print(f\"Number of features used: {model.n_features_in_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Test the Model\n",
    "\n",
    "Now we test how well our trained model performs on the **unseen test data** (the 30% we held back).\n",
    "\n",
    "The model has never seen these 45 flowers before - this is the real test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "print(f\"\\nCorrect predictions: {(y_pred == y_test).sum()} out of {len(y_test)}\")\n",
    "print(f\"Wrong predictions: {(y_pred != y_test).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Detailed Classification Report\n",
    "\n",
    "Let's see how well the model performs for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed report per species\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Predict New Flowers\n",
    "\n",
    "Now let's use our trained model to classify flowers we've never seen before.\n",
    "\n",
    "We'll create some example measurements and let the model predict the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new flower measurements (manually invented examples)\n",
    "new_flowers = [\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Small petals - probably Setosa\n",
    "    [6.5, 3.0, 5.2, 2.0],  # Large petals - probably Virginica\n",
    "    [5.7, 2.8, 4.1, 1.3],  # Medium petals - probably Versicolor\n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_flowers)\n",
    "\n",
    "# Display results\n",
    "print(\"Predictions for new flowers:\\n\")\n",
    "for i, flower in enumerate(new_flowers):\n",
    "    species = iris.target_names[predictions[i]]\n",
    "    print(f\"Flower {i+1}: {flower}\")\n",
    "    print(f\"  → Predicted species: {species}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Try Your Own!\n",
    "\n",
    "You can modify the `new_flowers` list above with your own measurements:\n",
    "- Sepal length (cm): typically 4.0 - 8.0\n",
    "- Sepal width (cm): typically 2.0 - 4.5\n",
    "- Petal length (cm): typically 1.0 - 7.0\n",
    "- Petal width (cm): typically 0.1 - 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Visualize the Decision Tree\n",
    "\n",
    "Let's look at the actual decision rules the model learned. Each box shows:\n",
    "- The decision rule (e.g., \"petal width <= 0.8\")\n",
    "- The gini impurity (measure of how mixed the classes are)\n",
    "- The number of samples at that node\n",
    "- The predicted class (color-coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Create a large figure for better readability\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot the decision tree\n",
    "plot_tree(\n",
    "    model,\n",
    "    feature_names=iris.feature_names,\n",
    "    class_names=iris.target_names,\n",
    "    filled=True,           # Color nodes by majority class\n",
    "    rounded=True,          # Rounded boxes look nicer\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "plt.title(\"Decision Tree Structure (max_depth=3)\", fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### Compare Different Models\n",
    "\n",
    "Let's see how different machine learning algorithms perform on the same Iris dataset.\n",
    "\n",
    "We'll compare:\n",
    "- **Decision Tree:** Uses yes/no questions (what we've been using)\n",
    "- **Random Forest:** Multiple decision trees voting together\n",
    "- **Logistic Regression:** Finds linear boundaries between classes\n",
    "- **Support Vector Machine (SVM):** Finds optimal separation planes\n",
    "- **K-Nearest Neighbors (KNN):** Classifies based on similar examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define different models to compare\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=3, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "print(\"Training and testing different models...\\n\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test on training data\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "\n",
    "    # Test on test data\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'train': train_accuracy,\n",
    "        'test': test_accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"{name}\")\n",
    "    print(f\"  Training Accuracy: {train_accuracy:.2%}\")\n",
    "    print(f\"  Test Accuracy:     {test_accuracy:.2%}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "model_names = list(results.keys())\n",
    "train_scores = [results[name]['train'] for name in model_names]\n",
    "test_scores = [results[name]['test'] for name in model_names]\n",
    "\n",
    "# Create bar chart\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, train_scores, width, label='Training Accuracy', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, test_scores, width, label='Test Accuracy', alpha=0.8)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Model Comparison: Training vs Test Accuracy', fontsize=14, pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0.85, 1.02])  # Focus on the relevant range\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "**What to look for:**\n",
    "- **High test accuracy:** The model works well on new data\n",
    "- **Similar train/test scores:** The model generalizes well (not overfitting)\n",
    "- **Train >> Test:** Warning sign of overfitting (memorizing training data)\n",
    "\n",
    "**Typical results for Iris:**\n",
    "- All models perform well (95-100%) because Iris is a simple dataset\n",
    "- Random Forest often has highest accuracy\n",
    "- Decision Tree is most interpretable (we can see the rules)\n",
    "- SVM and Logistic Regression work well for this linearly separable data\n",
    "\n",
    "**For real-world problems:**\n",
    "- Results vary much more between models\n",
    "- You'd need to test multiple algorithms\n",
    "- Consider speed, interpretability, and accuracy trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Summary: What We Learned\n",
    "\n",
    "### Machine Learning Type\n",
    "\n",
    "**This is Supervised Learning:**\n",
    "- We have labeled training data (features + known species)\n",
    "- The model learns the relationship between inputs and outputs\n",
    "- We \"supervise\" the learning by providing correct answers\n",
    "\n",
    "**This is Multi-Class Classification:**\n",
    "- We predict one of 3 categories (Setosa, Versicolor, Virginica)\n",
    "- As opposed to:\n",
    "  - **Binary Classification:** Only 2 classes (e.g., Spam/Not Spam, Fraud/Legitimate)\n",
    "  - **Regression:** Predicting continuous numbers (e.g., house prices, temperature)\n",
    "\n",
    "**Other ML types we didn't use:**\n",
    "- **Unsupervised Learning:** Finding patterns without labels (e.g., customer segmentation, clustering similar flowers without knowing species)\n",
    "- **Reinforcement Learning:** Learning through trial and error with rewards (e.g., game AI, robotics)\n",
    "\n",
    "### The Machine Learning Workflow\n",
    "\n",
    "We completed a full ML pipeline from start to finish:\n",
    "\n",
    "1. **Load Data:** Used the built-in Iris dataset (150 flowers, 4 measurements each)\n",
    "2. **Explore Data:** Examined the structure and statistics\n",
    "3. **Split Data:** 70% training, 30% testing (to prevent cheating)\n",
    "4. **Train Model:** Decision Tree learned patterns from 105 flowers\n",
    "5. **Test Model:** Evaluated on 45 unseen flowers\n",
    "6. **Make Predictions:** Classified new flowers based on measurements\n",
    "7. **Visualize:** Saw the actual decision rules the model uses\n",
    "8. **Compare Models:** Tested 5 different algorithms\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Features (X):** The input data we measure\n",
    "- Sepal length, sepal width, petal length, petal width\n",
    "\n",
    "**Target (y):** What we want to predict\n",
    "- Iris species (Setosa, Versicolor, Virginica)\n",
    "\n",
    "**Training:** The model learns patterns from labeled examples\n",
    "\n",
    "**Testing:** We evaluate how well it works on new, unseen data\n",
    "\n",
    "**Accuracy:** Percentage of correct predictions\n",
    "\n",
    "### Why Split Train/Test?\n",
    "\n",
    "If we test on the same data we trained on, we're cheating! The model has seen the answers. It's like giving students the exact exam questions before the test.\n",
    "\n",
    "By holding back 30% for testing, we get an honest measure of how well the model generalizes to new data.\n",
    "\n",
    "### Decision Tree Advantages\n",
    "\n",
    "✓ Easy to understand and visualize\n",
    "✓ Works with minimal data preprocessing\n",
    "✓ Can explain every prediction (interpretable)\n",
    "✓ Fast training and prediction\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**To improve this project, you could:**\n",
    "- Try different `max_depth` values (1, 5, 10, None)\n",
    "- Experiment with other `random_state` values\n",
    "- Use cross-validation for more robust evaluation\n",
    "- Test with your own custom flower measurements\n",
    "- Apply this to a different dataset (wine, digits, etc.)\n",
    "- Build a Streamlit app to make predictions interactively\n",
    "\n",
    "**To learn more:**\n",
    "- Try regression problems (predicting house prices, temperatures)\n",
    "- Explore unsupervised learning (clustering without labels)\n",
    "- Study other algorithms (Neural Networks, Gradient Boosting)\n",
    "- Learn about feature engineering\n",
    "- Explore hyperparameter tuning\n",
    "- Work with real-world messy data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
